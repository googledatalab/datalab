{
 "metadata": {
  "name": "",
  "signature": "sha256:c38c2511f31ec76493a470da2e5bd4b1b24d3fc0135a11e069e0bba5ee9fc7c7"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# BigQuery - Using Asynchronous APIs\n",
      "\n",
      "This notebook demonstrates how to use asynchronous versions of the pygcp.bigquery APIs from within a notebook.\n",
      "\n",
      "### In this notebook you will\n",
      "* Learn about the Query and Table APIs that have \\*_async versions\n",
      "* Learn how to use these APIs to return quickly so you can continue to do other work\n",
      "* Learn how to monitor the state of background async tasks and know when they are complete\n",
      "\n",
      "Related Links:\n",
      "\n",
      "* [BigQuery](https://cloud.google.com/bigquery/)\n",
      "\n",
      "----\n",
      "\n",
      "NOTE:\n",
      "\n",
      "* If you're new to notebooks, or want need an introduction to using BigQuery, check out the full [list](..) of notebooks.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import gcp.bigquery as bq"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Many if the APIs that exist on Query and Table objects in the gcp.bigquery library have async forms.\n",
      "\n",
      "These include:\n",
      "\n",
      "* Query.extract\n",
      "* Query.to_file\n",
      "* Query.execute\n",
      "* Table.load\n",
      "* Table.extract\n",
      "* Table.to_file\n",
      "* View.execute\n",
      "\n",
      "In each case, the signature is exactly the same; the only difference is that the async versions have an \\_async suffix on the method name and return Job objects.\n",
      "\n",
      "For example, the code below will attempt to extract the first 1000 rows of the natality sample table to a temporary file:\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t = bq.table('publicdata:samples.natality')\n",
      "j = t.sample(count=1000).to_file_async('/tmp/natality1000.csv')\n",
      "j"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "Job e69489a1-0f9b-4427-82f1-15b653f15f4f in progress"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Notice how the extract\\_async method returned a job with a GUID ID and a status. For a correct job on a very fast \n",
      "machine you may see 'completed' for the job status, but more likely you see 'in progress'.\n",
      "\n",
      "You can always check on the state of a job object by calling its is\\_complete method:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "j.is_complete"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "False"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To wait until a job completes we can call wait():"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "j.wait()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "Job e69489a1-0f9b-4427-82f1-15b653f15f4f completed"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Once it is complete, the fatal\\_error property will tell us if a job failed, while the errors property will inform us of any non-fatal errors that may have occurred:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Fatal: %s\" % str(j.fatal_error)\n",
      "print \"Non-fatal: %s\" % str(j.errors)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fatal: None\n",
        "Non-fatal: None\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Similarly, we can call the Job.failed method to test for success:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "j.failed"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "False"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "To see what happens with a failing job we can try a similar operation but with an extract using an invalid GCS name:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "try:\n",
      "  t = bq.table('publicdata:samples.natality')\n",
      "  j = t.sample(count=1000).extract_async('natality:1000.csv')\n",
      "except Exception as e:\n",
      "  print \"%s: %s\" % (str(type(e)), e)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<class 'gcp._util._job.JobError'>: Invalid extract destination URI 'natality:1000.csv'. Must be a valid Google Storage path.\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Notice how in this case we got a JobError exception.\n",
      "\n",
      "There are two useful utility functions in gcp.bigquery available for working with jobs, namely wait_any and wait_all. Each of these can take a reference to a job, or a list of jobs, plus an optional timeout. wait_any will return when at least one job has completed (or a timeout happens) while wait_all will return when all jobs have completed (or the timeout happens). In each case the return value is the list of complete jobs. We can illustrate this with the following code:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "q1 = bq.query('SELECT * FROM [publicdata:samples.natality] LIMIT 200')\n",
      "q2 = bq.query('SELECT * FROM [publicdata:samples.natality] LIMIT 2000')\n",
      "j1 = q1.execute_async(use_cache=False)\n",
      "j2 = q2.execute_async(use_cache=False)\n",
      "\n",
      "while True:\n",
      "    completed = bq.wait_any([j1, j2])\n",
      "    print str(completed)\n",
      "    if len(completed) == 2:\n",
      "        break\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[Job job_C9eIkrBdfjKp9fDqqUvb2u0vEk8 completed]\n",
        "[Job job_SlGbO0yBMOUQkZiHHVyeUN9UJxc completed, Job job_C9eIkrBdfjKp9fDqqUvb2u0vEk8 completed]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    }
   ],
   "metadata": {}
  }
 ]
}